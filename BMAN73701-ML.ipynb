{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4579e9e1-2d1d-45b7-91d6-4d72203ce624",
   "metadata": {},
   "source": [
    "# Coursework\n",
    "## Programming in Python for Business Analytics\n",
    "#### Group 19\n",
    "\n",
    "#### Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf67ac29-9b68-4db7-ab82-ee0dcc06d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries:\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee86fb92-bb97-4434-8d18-cc3b39f14c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data_py.csv')\n",
    "tasks = pd.read_csv('/Users/alexander/Documents/GitHub/PythonCoursework/data/tasks.csv')\n",
    "suppliers = pd.read_csv('/Users/alexander/Documents/GitHub/PythonCoursework/data/suppliers.csv')\n",
    "cost = pd.read_csv('/Users/alexander/Documents/GitHub/PythonCoursework/data/cost.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfdda828-86d4-4a0d-ab01-50c7ff15c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into test and train datasets, manually to preserve the groups\n",
    "X = dataset.drop(['Task ID','Supplier ID','Cost'], axis='columns')\n",
    "y = dataset['Cost']\n",
    "Groups = dataset['Task ID']\n",
    "\n",
    "all_tasks = Groups.unique()\n",
    "random.seed(42)\n",
    "TestGroup = np.random.choice(all_tasks, size=20, replace=False)\n",
    "\n",
    "test_loc = dataset['Task ID'].isin(list(TestGroup))\n",
    "\n",
    "X_test = X[test_loc]\n",
    "y_test = y[test_loc]\n",
    "X_train = X[~test_loc]\n",
    "y_train = y[~test_loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31d0eaff-3062-42ad-8c00-030c2f610cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Fitting a ridge regression model\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=0.5)\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge.score(X_test,y_test)\n",
    "y_pred = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cc0e0b6-421e-4d1c-ab26-34849a45e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Grouping by tasks and selecting a supplier for each test task\n",
    "# using the error formula provided calculate difference between true supplier and predicted supplier cost\n",
    "\n",
    "# Getting Task IDs for our predictions\n",
    "ids = dataset['Task ID'][test_loc].reset_index(drop=True)\n",
    "y_pred = pd.Series(y_pred, name=\"Predicted Cost\")\n",
    "\n",
    "y_pred_ids = pd.merge(ids, y_pred, right_index = True, left_index = True)\n",
    "pred_best_suppliers = y_pred_ids.groupby('Task ID')['Predicted Cost'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4062226e-18ea-4c7a-a8bc-a647ebb17967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the true cheapest suppliers for our test set\n",
    "true_best_suppliers = cost.groupby('Task ID')['Cost'].min()\n",
    "\n",
    "test_best_suppliers = true_best_suppliers[true_best_suppliers.index.isin(TestGroup)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cae39f3-784a-42e0-bcf3-ff5ed8ccd351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions to calculate errors and rmse\n",
    "def error_calc(true_min_costs, predicted_min_cost):\n",
    "   error = true_min_costs - predicted_min_cost\n",
    "   return error\n",
    "\n",
    "def rmse_calc(error_array):\n",
    "    squared_errors = error_array*error_array\n",
    "    rss = np.sum(squared_errors)\n",
    "    value = np.sqrt(rss/len(error_array))\n",
    "    return value\n",
    "\n",
    "ridge_error = error_calc(test_best_suppliers, pred_best_suppliers)\n",
    "ridge_rmse = rmse_calc(ridge_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0facd553-5c37-43c1-b0b5-634197e06efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task ID\n",
      "T107    0.013728\n",
      "T108   -0.022155\n",
      "T113   -0.031174\n",
      "T127   -0.018289\n",
      "T14    -0.051290\n",
      "T16    -0.045721\n",
      "T28    -0.038868\n",
      "T34    -0.096904\n",
      "T39    -0.005387\n",
      "T40    -0.033426\n",
      "T45    -0.017008\n",
      "T6     -0.043307\n",
      "T8     -0.033803\n",
      "T83    -0.006378\n",
      "T85    -0.036355\n",
      "T87    -0.039659\n",
      "T88    -0.025602\n",
      "T93     0.026752\n",
      "T98    -0.001158\n",
      "T99     0.004425\n",
      "dtype: float64\n",
      "0.0363241273831713\n"
     ]
    }
   ],
   "source": [
    "# Results for an initial ridge model\n",
    "print(ridge_error)\n",
    "print(ridge_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21978e5e-cf7b-487b-9b64-92cd76734330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Performing cross validation\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "train_tasks = dataset['Task ID'][~test_loc]\n",
    "\n",
    "ridge_cv = Ridge(alpha=0.5)\n",
    "logo = LeaveOneGroupOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4911511-b346-4335-8880-858fdd72d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our scoring function:\n",
    "# Since the test set for each fold of the cross validation only contains one group\n",
    "# we can just find the minimums of each array, then compute rmse from that\n",
    "\n",
    "def error_scoring(all_trues, all_preds):\n",
    "    error = all_trues.min() - all_preds.min()\n",
    "    return error\n",
    "error_scorer = make_scorer(error_scoring)\n",
    "\n",
    "scores = cross_val_score(ridge_cv, X_train, y_train, cv=logo, groups=train_tasks, scoring=error_scorer)\n",
    "cv_rmse = rmse_calc(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
